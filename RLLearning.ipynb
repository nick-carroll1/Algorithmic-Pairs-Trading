{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses QuantConnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuantBook Analysis Tool \n",
    "# For more information see [https://www.quantconnect.com/docs/research/overview]\n",
    "qb = QuantBook()\n",
    "spy = qb.AddEquity('SPY')\n",
    "msft = qb.AddEquity('MSFT')\n",
    "# start_time = datetime(2017, 1, 1)\n",
    "# end_time = datetime(2021, 1, 1)\n",
    "# history = qb.History(qb.Securities.Keys, start_time, end_time, Resolution.Daily)\n",
    "history = qb.History(qb.Securities.Keys, 360, Resolution.Daily)\n",
    "\n",
    "# Indicator Analysis\n",
    "# bbdf = qb.Indicator(BollingerBands(30, 2), spy.Symbol, 360, Resolution.Daily)\n",
    "# bbdf.drop('standarddeviation', 1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history['close'].unstack(level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['Spread'] = history['MSFT R735QTJ8XC9X'] - history ['SPY R735QTJ8XC9X']\n",
    "history = history.rename(columns = {'MSFT R735QTJ8XC9X': 'MSFT','SPY R735QTJ8XC9X': 'SPY'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, history, render_mode=None):\n",
    "\n",
    "        # Observations are dictionaries with the MSFT's and SPY's prices.\n",
    "        # For this purpose, assume prices cannot go above 1,000.\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"msft\": gym.spaces.Box(low = 0, high = 1_000, shape = (1,), dtype=np.float32),\n",
    "                \"spy\": gym.spaces.Box(low = 0, high = 1_000, shape = (1,), dtype=np.float32),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self._msft = history.loc[:, 'MSFT']\n",
    "        self._spy = history.loc[:, 'SPY']\n",
    "\n",
    "        self.date = 0\n",
    "\n",
    "        self.portfolio = {'MSFT': 0, 'SPY': 0, 'Cash': 100_000}\n",
    "        self.cost_basis = 0\n",
    "        \n",
    "        # We have 3 actions, corresponding to \"Long\", \"Hold\", \"Short\"\n",
    "        self.action_space = gym.spaces.Discrete(3)\n",
    "\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to \n",
    "        the action taken.\n",
    "        I.e. 0 corresponds to \"Long\", which will multiply our portfolio by 1.\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            0: 'Long',\n",
    "            1: 'Hold',\n",
    "            2: 'Short'\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"msft\": self._msft.iloc[self.date], \"spy\": self._spy.iloc[self.date]}\n",
    "\n",
    "    def _get_info(self):\n",
    "        return self.portfolio\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        # super().reset(seed=seed)\n",
    "        self.date = 0\n",
    "        observation = self._get_obs()\n",
    "        self.portfolio = {'MSFT': 0, 'SPY': 0, 'Cash': 100_000}\n",
    "        self.cost_basis = 0\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        fees = 0\n",
    "        direction = self._action_to_direction[action]\n",
    "        if direction == 'Hold':\n",
    "            pass\n",
    "        elif direction == 'Long':\n",
    "            if self.portfolio['MSFT'] > 0:\n",
    "                pass\n",
    "            else:\n",
    "                self.portfolio['Cash'] += self.portfolio['MSFT'] * observation['msft'] + self.portfolio['SPY'] * observation['spy'] - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                fees += - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                self.portfolio['MSFT'] = self.portfolio['Cash'] // observation['msft']\n",
    "                self.portfolio['SPY'] = - self.portfolio['Cash'] // observation['spy']\n",
    "                self.cost_basis = self.portfolio[\"Cash\"]\n",
    "                self.portfolio[\"Cash\"] += self.portfolio['MSFT'] * observation['msft'] + self.portfolio['SPY'] * observation['spy'] - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                fees += - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "        elif direction == \"Short\":\n",
    "            if self.portfolio['MSFT'] < 0:\n",
    "                pass\n",
    "            else:\n",
    "                self.portfolio['Cash'] += self.portfolio['MSFT'] * observation['msft'] + self.portfolio['SPY'] * observation['spy'] - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                fees += - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                self.portfolio['MSFT'] = - self.portfolio['Cash'] / observation['msft']\n",
    "                self.portfolio['SPY'] = self.portfolio['Cash'] / observation['spy']\n",
    "                self.cost_basis = self.portfolio[\"Cash\"]\n",
    "                self.portfolio[\"Cash\"] += self.portfolio['MSFT'] * observation['msft'] + self.portfolio['SPY'] * observation['spy'] - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "                fees += - .005 * (self.portfolio['SPY'] + self.portfolio['MSFT'])\n",
    "            \n",
    "        self.date += 1\n",
    "        \n",
    "        # An episode is done if the agent has reached the target\n",
    "        terminated = self.date > self._msft.shape[0] - 3\n",
    "\n",
    "        next_observation = self._get_obs()\n",
    "        reward = self.portfolio['MSFT'] * (next_observation['msft']  - observation ['msft']) + self.portfolio['SPY'] * (next_observation['spy'] - observation['spy']) + fees\n",
    "        \n",
    "        # if self.render_mode == \"human\":\n",
    "        #     self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockEnv(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_pass(predictions, epsilon, env):\n",
    "    state = env.reset()\n",
    "    record = {}\n",
    "    for i in range(500):\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = predictions[i]\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        record[i] = {'MSFT Price': n_state['msft'], 'SPY Price': n_state['spy'], 'Portfolio-MSFT': info['MSFT'], 'Portfolio-SPY': info['SPY'], 'Portfolio-Cash': info['Cash'], 'reward': reward, 'action': action}\n",
    "        if done:\n",
    "            break\n",
    "    return pd.DataFrame(record).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_pass_w_warmup(predictions, epsilon, env, sequence_length):\n",
    "    state = env.reset()\n",
    "    record = {}\n",
    "    for i in range(500):\n",
    "        if i >= sequence_length - 1 and i <= predictions.shape[0]:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = predictions[i - sequence_length + 1]\n",
    "            n_state, reward, done, info = env.step(action)\n",
    "            record[i] = {'MSFT Price': n_state['msft'], 'SPY Price': n_state['spy'], 'Portfolio-MSFT': info['MSFT'], 'Portfolio-SPY': info['SPY'], 'Portfolio-Cash': info['Cash'], 'reward': reward, 'action': action}\n",
    "        else:\n",
    "            action = 1\n",
    "            n_state, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "    return pd.DataFrame(record).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_pass = run_pass(None, 1000, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_action = ((this_pass['MSFT Price'] - this_pass['SPY Price']).shift(-1) - (this_pass['MSFT Price'] - this_pass['SPY Price'])).apply(lambda x: 0 if x > 0 else 2).to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_mean = run_pass(None, 1000, env).mean()\n",
    "bootstrap_std = run_pass(None, 1000, env).std()\n",
    "for epochs in range(100):\n",
    "    bootstrap_mean = pd.concat((bootstrap_mean, run_pass(None, 1000, env).mean()), axis = 1)\n",
    "    bootstrap_std = pd.concat((bootstrap_std, run_pass(None, 1000, env).std()), axis = 1)\n",
    "# bootstrap = (bootstrap_mean.mean(axis = 1)[['MSFT Price', 'SPY Price', 'action']], bootstrap_std.mean(axis = 1)[['MSFT Price', 'SPY Price', 'action']])\n",
    "bootstrap = (bootstrap_mean.mean(axis = 1)[['MSFT Price', 'SPY Price']], bootstrap_std.mean(axis = 1)[['MSFT Price', 'SPY Price']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn as Unsequenced State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = MLPRegressor(learning_rate_init = .01)\n",
    "# q_target = MLPRegressor(learning_rate_init = .01)\n",
    "\n",
    "# init = True\n",
    "# this_pass = run_pass(None, 40)\n",
    "# average_output = np.zeros((this_pass.shape[0], 3))\n",
    "# counter = np.ones((this_pass.shape[0], 3))\n",
    "# for epochs in range(100):\n",
    "#     this_output = np.zeros((this_pass.shape[0], 3))\n",
    "#     this_pass = run_pass(q.predict(x)[:, :3].argmax(1) if not init else ideal_action, 20 / (epochs + 1))\n",
    "#     x = this_pass.loc[:, ['MSFT Price', 'SPY Price', 'Portfolio-MSFT', 'Portfolio-SPY', 'Portfolio-Cash']]\n",
    "#     mean = bootstrap[0]\n",
    "#     std = bootstrap[1]\n",
    "#     x = (x - mean) / std\n",
    "#     for index in this_pass.index:\n",
    "#         this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "#         this_counter = np.zeros((this_pass.shape[0], 3))\n",
    "#         this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "#         counter = counter + this_counter\n",
    "#     average_output = ((counter - 1) * average_output + this_output) / counter\n",
    "    \n",
    "#     if not init:\n",
    "#         q_target.coefs_ = q.coefs_\n",
    "#     else:\n",
    "#         y_init = 100 * np.random.rand(this_pass.shape[0] - 1, 3 + x.shape[1])\n",
    "#         q_target.partial_fit(x[:-1], y_init)\n",
    "#         init = False\n",
    "#     y_target = np.concatenate(((average_output + .000009 * q_target.predict(q_target.predict(x)[:, 3:])[:, :3].max(1).reshape(-1, 1) / 1.0003)[:-1], x.to_numpy()[1:]), axis = 1)\n",
    "#     for i in range(5):\n",
    "#         q.partial_fit(x[:-1], y_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn with MLP as Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = MLPRegressor(learning_rate_init = .01)\n",
    "q_target = MLPRegressor(learning_rate_init = .01)\n",
    "\n",
    "init = True\n",
    "this_pass = run_pass(None, 40)\n",
    "average_output = np.zeros((this_pass.shape[0], 3))\n",
    "counter = np.zeros((this_pass.shape[0], 3))\n",
    "for epochs in range(30):\n",
    "    this_output = np.zeros((this_pass.shape[0], 3))\n",
    "    this_pass = run_pass(None, 40 / (epochs + 1))\n",
    "    x = this_pass.loc[:, ['MSFT Price', 'SPY Price']]\n",
    "    mean = bootstrap[0]\n",
    "    std = bootstrap[1]\n",
    "    x = (x - mean) / std\n",
    "    for index in this_pass.index:\n",
    "        this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "        this_counter = np.zeros((this_pass.shape[0], 3))\n",
    "        this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "    counter = counter + this_counter\n",
    "    average_output = (np.where(counter == 0, 0, counter - 1) * average_output + this_output) / np.where(counter == 0, 1, counter)\n",
    "    \n",
    "    sequence_length = 15\n",
    "    batched = np.stack((x[:sequence_length], x[1:1 + sequence_length]))\n",
    "    for i in range(2, x.shape[0] - sequence_length):\n",
    "        batched = np.concatenate((batched, x[i: i + sequence_length].to_numpy().reshape(1, sequence_length, x.shape[1])), axis = 0)\n",
    "\n",
    "    flattened_batched = batched.reshape(batched.shape[0], -1)\n",
    "\n",
    "    predicted_batches = batched.copy()\n",
    "    \n",
    "    if not init:\n",
    "        q_target.coefs_ = q.coefs_\n",
    "    else:\n",
    "        y_init = 100 * np.random.rand(flattened_batched.shape[0], 3 + x.shape[1])\n",
    "        q_target.partial_fit(flattened_batched, y_init)\n",
    "        init = False\n",
    "\n",
    "    \n",
    "    predicted_batches[1:, -1, :] = q_target.predict(flattened_batched)[:-1, 3:]\n",
    "\n",
    "    y_target = np.concatenate(((average_output[sequence_length: -1] + .9 * q_target.predict(predicted_batches.reshape(batched.shape[0], -1))[1:].max(1).reshape(-1, 1) / 1.0003), x.to_numpy()[sequence_length + 1:]), axis = 1)\n",
    "\n",
    "\n",
    "    \n",
    "    # # y_target = np.concatenate(((average_output + .000009 * q_target.predict(q_target.predict(x)[:, 3:])[:, :3].max(1).reshape(-1, 1) / 1.0003)[:-1], x.to_numpy()[1:]), axis = 1)\n",
    "    for i in range(5):\n",
    "        q.partial_fit(flattened_batched[:-1], y_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn Q-Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init = False\n",
    "this_pass = run_pass(None, 40)\n",
    "all_outputs = np.zeros((this_pass.shape[0], 3))\n",
    "average_output = np.zeros((this_pass.shape[0], 3))\n",
    "counter = np.ones((this_pass.shape[0], 3))\n",
    "for epochs in range(10):\n",
    "    this_output = np.zeros((this_pass.shape[0], 3))\n",
    "    this_pass = run_pass(average_output.argmax(1), 100000 / (epochs + 1))\n",
    "    for index in this_pass.index:\n",
    "        this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "        this_counter = np.zeros((this_pass.shape[0], 3))\n",
    "        this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "        counter = counter + this_counter\n",
    "    average_output = ((counter - 1) * average_output + this_output) / counter\n",
    "    # if epochs > 0:\n",
    "    #     if len(all_outputs.shape) > 2:\n",
    "    #         all_outputs = np.concatenate((all_outputs, this_output.reshape(-1, this_output.shape[0], this_output.shape[1])), axis = 0)\n",
    "    #     else:\n",
    "    #         all_outputs = np.stack((this_output, all_outputs))\n",
    "    # else:\n",
    "    #     all_outputs = this_output\n",
    "(average_output.argmax(1) == ideal_action).sum(), len(ideal_action)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# q = LinearRegression()\n",
    "# q_target = LinearRegression()\n",
    "\n",
    "# scores = []\n",
    "# init = True\n",
    "# this_pass = run_pass(None, 40)\n",
    "# average_output = np.zeros((this_pass.shape[0], 3))\n",
    "# counter = np.ones((this_pass.shape[0], 3))\n",
    "# for epochs in range(10000):\n",
    "#     this_output = np.zeros((this_pass.shape[0], 3))\n",
    "#     this_pass = run_pass(q.predict(x)[:, :3].argmax(1) if not init else ideal_action, 20 / (epochs + 1))\n",
    "#     x = this_pass.loc[:, ['MSFT Price', 'SPY Price', 'Portfolio-MSFT', 'Portfolio-SPY', 'Portfolio-Cash']]\n",
    "#     for index in this_pass.index:\n",
    "#         this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "#         this_counter = np.zeros((this_pass.shape[0], 3))\n",
    "#         this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "#         counter = counter + this_counter\n",
    "#     average_output = ((counter - 1) * average_output + this_output) / counter\n",
    "    \n",
    "#     if not init:\n",
    "#         q_target.coef_ = q.coef_\n",
    "#     else:\n",
    "#         y_init = 100 * np.random.rand(this_pass.shape[0] - 1, 3 + x.shape[1])\n",
    "#         q_target.fit(x[:-1], y_init)\n",
    "#         init = False\n",
    "#     y_target = np.concatenate(((average_output + .9 * q_target.predict(q_target.predict(x)[:, 3:])[:, :3].max(1).reshape(-1, 1) / 1.0003)[:-1], x.to_numpy()[1:]), axis = 1)\n",
    "#     if epochs % 1 == 0:\n",
    "#         q.fit(x[:-1], y_init)\n",
    "\n",
    "#     scores.append(q.score(x[:-1], y_init))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "        if len(x.size()) == 2:\n",
    "            return self.dropout(torch.cat((x.reshape(x.size(0), -1, x.size(1)), self.pe[:x.size(0), :, :4]), axis = -1)).transpose(0, 1)\n",
    "        else:\n",
    "            return self.dropout(torch.cat((x, self.pe[:x.size(0), :, :4].expand(-1, x.size(1), -1)), axis = -1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, length, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        try:\n",
    "            from torch.nn import Transformer, TransformerEncoder, TransformerEncoderLayer\n",
    "        except BaseException as e:\n",
    "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or '\n",
    "                              'lower.') from e\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=ninp, \n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "            )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=nlayers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=ninp, \n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=decoder_layer,\n",
    "            num_layers=nlayers, \n",
    "            norm=None\n",
    "            )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(\n",
    "            ninp\n",
    "        )\n",
    "\n",
    "        self.hidden1= nn.Linear(\n",
    "            in_features = ninp * length,\n",
    "            out_features = 100\n",
    "        )\n",
    "\n",
    "        self.hidden2 = nn.Linear(\n",
    "            in_features = 100,\n",
    "            out_features = 5\n",
    "        )\n",
    "\n",
    "        self.linear1 = nn.Linear(\n",
    "            in_features=length,\n",
    "            out_features=1\n",
    "            )\n",
    "\n",
    "        self.linear2 = nn.Linear(\n",
    "            in_features = ninp,\n",
    "            out_features = 3\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear1.bias.data.zero_()\n",
    "        self.linear1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear2.bias.data.zero_()\n",
    "        self.linear2.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, has_mask=True):\n",
    "        if has_mask:\n",
    "            # device = src.device\n",
    "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                mask = self._generate_square_subsequent_mask(src.size(0) if len(src.size()) == 2 else src.size(1))#.to(device)\n",
    "                self.src_mask = mask\n",
    "\n",
    "        else:\n",
    "            self.src_mask = None\n",
    "        # print(f\"input: {src.shape}\")\n",
    "        src = self.pos_encoder(src)\n",
    "        # print(f\"pos encoded: {src.shape}\")\n",
    "        encoder_output = self.encoder(src, mask = self.src_mask)\n",
    "        # print(f\"transformer encoded: {encoder_output.shape}\")\n",
    "        # output = self.decoder(\n",
    "        #     tgt=src,\n",
    "        #     memory=encoder_output,\n",
    "        #     tgt_mask=self.src_mask,\n",
    "        #     memory_mask=self.src_mask\n",
    "        #     )\n",
    "        # output = self.norm1(src)\n",
    "        # print(src.shape)\n",
    "        output = self.hidden1(encoder_output.reshape(encoder_output.size(0), -1))\n",
    "        # print(f\"hidden layer 1: {output.shape}\")\n",
    "        # print(output.shape)\n",
    "        output = self.hidden2(output)\n",
    "        # print(f\"hidden Layer 2: {output.shape}\")\n",
    "        # print(output.shape)\n",
    "        # output = self.linear1(output.transpose(-2, -1)).transpose(-2, -1)\n",
    "        # output = self.linear2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def train_one_epoch(q, flattened_batched, y_target):\n",
    "\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = q(flattened_batched)\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    loss = loss_fn(outputs, y_target)\n",
    "    loss.backward()\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, q, outputs\n",
    "\n",
    "    # # # Gather data and report\n",
    "    # # running_loss += loss.item()\n",
    "\n",
    "    # MLP Code Below\n",
    "    \n",
    "    # q.partial_fit(flattened_batched, y_target)\n",
    "\n",
    "    # return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_pass(this_pass, average_output, counter, q, q_target, init):\n",
    "\n",
    "\n",
    "    ## Code for Torch\n",
    "\n",
    "    this_output = torch.zeros((this_pass.shape[0], 3))\n",
    "    this_counter = torch.zeros((this_pass.shape[0], 3))\n",
    "    this_pass = run_pass(None if not init else ideal_action, 40)\n",
    "    x = this_pass.loc[:, ['MSFT Price', 'SPY Price']]\n",
    "    mean = bootstrap[0]\n",
    "    std = bootstrap[1]\n",
    "    x = torch.from_numpy(((x - mean) / std).to_numpy()).to(torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index in this_pass.index:\n",
    "            this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "            this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "        counter += this_counter\n",
    "        average_output = (torch.where(counter == 0, 0, counter - 1) * average_output + this_output) / torch.where(counter == 0, 1, counter)\n",
    "    \n",
    "        sequence_length = 15\n",
    "        batched = torch.stack((x[:sequence_length], x[1:1 + sequence_length]))\n",
    "        for i in range(2, x.shape[0] - sequence_length):\n",
    "            batched = torch.cat((batched, x[i: i + sequence_length].reshape(1, sequence_length, x.shape[1])), axis = 0)\n",
    "\n",
    "        # flattened_batched = batched.reshape(batched.size(0), -1)\n",
    "\n",
    "        predicted_batches = batched.detach().clone()\n",
    "\n",
    "        predicted_batches[1:, -1, :] = q_target(batched)[:-1, 3:]\n",
    "        # predicted_batches[1:, -1, :] = q_target(flattened_batched)[:-1, 3:] \n",
    "    \n",
    "        y_target = torch.cat(((average_output[sequence_length: -1] + .9 * q_target(predicted_batches)[1:, 3:].max(1).values.reshape(-1, 1) / 1.0003), x[sequence_length + 1:]), axis = 1)\n",
    "        # y_target = torch.cat(((average_output[sequence_length: -1] + .9 * q_target(predicted_batches.reshape(batched.shape[0], -1))[1:, 3:].max(1).values.reshape(-1, 1) / 1.0003), x[sequence_length + 1:]), axis = 1)\n",
    "\n",
    "    for i in range(5):\n",
    "        # loss, q, outputs = train_one_epoch(q, flattened_batched[:-1], y_target)\n",
    "        loss, q, outputs = train_one_epoch(q, batched[:-1], y_target)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_parameters = [eachParameter for eachParameter in q.parameters()]\n",
    "        for i, eachParameter in enumerate(q_target.parameters()):\n",
    "            eachParameter = eachParameter.copy_(q_parameters[i])\n",
    "\n",
    "    return loss, average_output, counter, outputs, y_target, q, q_target, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_average_output(average_output, counter):\n",
    "    for passes in range(50):\n",
    "        this_pass = run_pass(ideal_action, 1000)\n",
    "        this_output = np.zeros((this_pass.shape[0], 3))\n",
    "        this_counter = np.zeros((this_pass.shape[0], 3))\n",
    "        for index in this_pass.index:\n",
    "            this_output[index, int(this_pass.loc[index, 'action'])] = this_pass.loc[index, 'reward']\n",
    "            this_counter[index, int(this_pass.loc[index, 'action'])] = 1\n",
    "        counter = counter + this_counter\n",
    "        average_output = (np.where(counter == 0, 0, counter - 1) * average_output + this_output) / np.where(counter == 0, 1, counter)\n",
    "    return average_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = TransformerModel(15, 6, 6, 6, 2)\n",
    "q_target = TransformerModel(15, 6, 6, 6, 2)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "# Optimizers specified in the torch.optim package\n",
    "# optimizer = SGD(q.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = Adam(q.parameters(), lr=0.01)\n",
    "\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 75\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "init = True\n",
    "average_output = torch.zeros((this_pass.shape[0], 3))\n",
    "counter = torch.zeros((this_pass.shape[0], 3))\n",
    "# average_output = prep_average_output(average_output, counter)\n",
    "this_output = torch.zeros((this_pass.shape[0], 3))\n",
    "this_pass = run_pass(ideal_action, 10000)\n",
    "x = torch.from_numpy(this_pass.loc[:, ['MSFT Price', 'SPY Price', 'Portfolio-MSFT', 'Portfolio-SPY', 'Portfolio-Cash']].to_numpy()).to(torch.float32)\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # q.train(False)\n",
    "    # q_predictions = q(x).argmax(1).numpy()\n",
    "\n",
    "    # if not init and epoch % 5 == 0:\n",
    "    #     q_target.coefs_ = q.coefs_\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    q.train(True)\n",
    "\n",
    "    this_pass = run_pass(None if epoch > EPOCHS else ideal_action, 1000 / (epoch + 1))\n",
    "    avg_loss, average_output, counter, outputs, y_target, q, q_target, init = train_one_pass(this_pass, average_output, counter, q, q_target, init)\n",
    "    print(f'EPOCH {epoch_number + 1}: {avg_loss}')\n",
    "\n",
    "    # if epoch % 5 == 0:\n",
    "    #     with torch.no_grad():\n",
    "    #         # We don't need gradients on to do reporting\n",
    "    #         q.train(False)\n",
    "    #         q_parameters = [eachParameter for eachParameter in q.parameters()]\n",
    "    #         for i, eachParameter in enumerate(q_target.parameters()):\n",
    "    #             eachParameter = eachParameter.copy_(q_parameters[i])\n",
    "    \n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72db1ef4dcd6e2344e9289c13171ece59739274764f83c0b8f73f911c07b82ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
